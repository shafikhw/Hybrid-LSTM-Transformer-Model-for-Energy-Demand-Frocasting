{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk4rGy1oQGLP"
      },
      "source": [
        "\n",
        "# Step 1: Prepare the Data\n",
        "In this step, we will prepare the data for our LSTM model. The dataset contains several features such as **Global_active_power, Global_reactive_power, Voltage, Global_intensity, and Sub_metering_1, Sub_metering_2, Sub_metering_3**. We need to clean the data, handle missing values, and convert the datetime columns into a proper datetime format.\n",
        "\n",
        "We'll also scale the features and create sequences for the LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "id": "_8IXxfoYQRgA",
        "outputId": "17027498-5b67-4e57-eef5-1405a6ee3470"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\shafi\\AppData\\Local\\Temp\\ipykernel_50692\\2492463855.py:7: FutureWarning: Support for nested sequences for 'parse_dates' in pd.read_csv is deprecated. Combine the desired columns with pd.to_datetime after parsing instead.\n",
            "  data = pd.read_csv(url, sep=\";\", parse_dates=[[0, 1]], infer_datetime_format=True)\n",
            "C:\\Users\\shafi\\AppData\\Local\\Temp\\ipykernel_50692\\2492463855.py:7: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  data = pd.read_csv(url, sep=\";\", parse_dates=[[0, 1]], infer_datetime_format=True)\n",
            "C:\\Users\\shafi\\AppData\\Local\\Temp\\ipykernel_50692\\2492463855.py:7: DtypeWarning: Columns (2,3,4,5,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  data = pd.read_csv(url, sep=\";\", parse_dates=[[0, 1]], infer_datetime_format=True)\n",
            "C:\\Users\\shafi\\AppData\\Local\\Temp\\ipykernel_50692\\2492463855.py:7: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  data = pd.read_csv(url, sep=\";\", parse_dates=[[0, 1]], infer_datetime_format=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values:\n",
            " Global_active_power          0\n",
            "Global_reactive_power        0\n",
            "Voltage                      0\n",
            "Global_intensity             0\n",
            "Sub_metering_1               0\n",
            "Sub_metering_2               0\n",
            "Sub_metering_3           25979\n",
            "dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\shafi\\AppData\\Local\\Temp\\ipykernel_50692\\2492463855.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
            "  data.fillna(method='ffill', inplace=True)  # Forward fill to replace NaNs\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date_Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>0.374796</td>\n",
              "      <td>0.300719</td>\n",
              "      <td>0.376090</td>\n",
              "      <td>0.377593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.548387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>0.478363</td>\n",
              "      <td>0.313669</td>\n",
              "      <td>0.336995</td>\n",
              "      <td>0.473029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.516129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>0.479631</td>\n",
              "      <td>0.358273</td>\n",
              "      <td>0.326010</td>\n",
              "      <td>0.473029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0250</td>\n",
              "      <td>0.548387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>0.480898</td>\n",
              "      <td>0.361151</td>\n",
              "      <td>0.340549</td>\n",
              "      <td>0.473029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.548387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>0.325005</td>\n",
              "      <td>0.379856</td>\n",
              "      <td>0.403231</td>\n",
              "      <td>0.323651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.548387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     Global_active_power  Global_reactive_power   Voltage  \\\n",
              "Date_Time                                                                   \n",
              "2006-12-16 17:24:00             0.374796               0.300719  0.376090   \n",
              "2006-12-16 17:25:00             0.478363               0.313669  0.336995   \n",
              "2006-12-16 17:26:00             0.479631               0.358273  0.326010   \n",
              "2006-12-16 17:27:00             0.480898               0.361151  0.340549   \n",
              "2006-12-16 17:28:00             0.325005               0.379856  0.403231   \n",
              "\n",
              "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
              "Date_Time                                                               \n",
              "2006-12-16 17:24:00          0.377593             0.0          0.0125   \n",
              "2006-12-16 17:25:00          0.473029             0.0          0.0125   \n",
              "2006-12-16 17:26:00          0.473029             0.0          0.0250   \n",
              "2006-12-16 17:27:00          0.473029             0.0          0.0125   \n",
              "2006-12-16 17:28:00          0.323651             0.0          0.0125   \n",
              "\n",
              "                     Sub_metering_3  \n",
              "Date_Time                            \n",
              "2006-12-16 17:24:00        0.548387  \n",
              "2006-12-16 17:25:00        0.516129  \n",
              "2006-12-16 17:26:00        0.548387  \n",
              "2006-12-16 17:27:00        0.548387  \n",
              "2006-12-16 17:28:00        0.548387  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Load the dataset\n",
        "url = \"household_power_consumption.txt\"  # Replace with your actual file path\n",
        "data = pd.read_csv(url, sep=\";\", parse_dates=[[0, 1]], infer_datetime_format=True)\n",
        "\n",
        "# Convert 'Date_Time' into the proper datetime format\n",
        "data['Date_Time'] = pd.to_datetime(data['Date_Time'], format='%d/%m/%Y %H:%M:%S')\n",
        "\n",
        "# Sort data by datetime to ensure it's in the correct order\n",
        "data = data.sort_values(by='Date_Time')\n",
        "\n",
        "# Set the Date_Time column as the index\n",
        "data.set_index('Date_Time', inplace=True)\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", data.isnull().sum())\n",
        "\n",
        "# Replace '?' with NaN and drop or fill missing values\n",
        "data.replace('?', np.nan, inplace=True)\n",
        "data.fillna(method='ffill', inplace=True)  # Forward fill to replace NaNs\n",
        "\n",
        "# Convert all columns to numeric values (since some might be read as strings)\n",
        "data = data.apply(pd.to_numeric)\n",
        "\n",
        "# Scaling the data (Min-Max Scaling)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "# Convert the scaled data back into a DataFrame\n",
        "scaled_data_df = pd.DataFrame(scaled_data, columns=data.columns, index=data.index)\n",
        "\n",
        "# Check the scaled data\n",
        "scaled_data_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcqYN_S1Q4IX"
      },
      "source": [
        "**Create sequences of length `seq_length` and corresponding targets**\n",
        "\n",
        "- Let `seq_length` be the number of past timesteps the model uses (e.g. 10).\n",
        "- For each index `i`,\n",
        "  - **X[i]** = data at times `i, i+1, …, i+seq_length-1` for *all* features\n",
        "  - **y[i]** = Global_active_power at time `i+seq_length`\n",
        "- Finally, split into training, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgSrPNW-Q6TP",
        "outputId": "07202f7e-a548-4c08-9f59-11472450f5d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input shape:  (2075249, 10, 7)\n",
            "Target shape: (2075249,)\n",
            "Train/Val/Test shapes:\n",
            "  X_train: (1452674, 10, 7), y_train: (1452674,)\n",
            "  X_val:   (311287, 10, 7),   y_val:   (311287,)\n",
            "  X_test:  (311288, 10, 7),  y_test:  (311288,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Choose sequence length\n",
        "seq_length = 10\n",
        "\n",
        "# Convert scaled DataFrame to NumPy array\n",
        "all_data = scaled_data_df.values  # shape = (n_samples, n_features)\n",
        "\n",
        "# Prepare containers\n",
        "X, y = [], []\n",
        "\n",
        "# Build sequences\n",
        "for i in range(len(all_data) - seq_length):\n",
        "    # window of features\n",
        "    X.append(all_data[i : i + seq_length])\n",
        "    # target is Global_active_power at next timestep\n",
        "    y.append(all_data[i + seq_length, 0])\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X = np.array(X)  # shape = (n_samples-seq_length, seq_length, n_features)\n",
        "y = np.array(y)  # shape = (n_samples-seq_length,)\n",
        "\n",
        "print(f\"Input shape:  {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Example split: 70% train, 15% val, 15% test\n",
        "n_total = X.shape[0]\n",
        "n_train = int(n_total * 0.70)\n",
        "n_val   = int(n_total * 0.15)\n",
        "\n",
        "X_train, y_train = X[:n_train], y[:n_train]\n",
        "X_val,   y_val   = X[n_train : n_train + n_val], y[n_train : n_train + n_val]\n",
        "X_test,  y_test  = X[n_train + n_val :],      y[n_train + n_val :]\n",
        "\n",
        "print(f\"Train/Val/Test shapes:\")\n",
        "print(f\"  X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print(f\"  X_val:   {X_val.shape},   y_val:   {y_val.shape}\")\n",
        "print(f\"  X_test:  {X_test.shape},  y_test:  {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVkDqPyIRL-P"
      },
      "source": [
        "**Step 3: Design the LSTM Architecture**\n",
        "\n",
        "We’ll build a stacked LSTM network with aggressive regularization and a learning-rate scheduler to maximize accuracy. Key choices:\n",
        "\n",
        "- **Two LSTM layers** (128 → 64 units) to capture both long- and short-term dependencies.  \n",
        "- **Dropout (0.3)** after each LSTM for regularization.  \n",
        "- **Dense bottleneck** (32 units, ReLU) to learn a compact representation before the final output.  \n",
        "- **Adam optimizer** with an initial learning rate of 1e-3.  \n",
        "- **Loss = MSE**, tracking MAE as a secondary metric.  \n",
        "- **Callbacks**:  \n",
        "  - **EarlyStopping** (patience=15) to halt when val_loss stops improving.  \n",
        "  - **ReduceLROnPlateau** (factor=0.5, patience=5) to lower the learning rate on plateaus.  \n",
        "  - **ModelCheckpoint** to save the best weights.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_laBR-_rbOV",
        "outputId": "26173729-a5cb-46f7-b8fe-4924e6356d0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.2)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.71.0rc2)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.9.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: rich in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (1.26.20)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (6.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\shafi\\anaconda3\\envs\\nn_sp\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\shafi\\appdata\\roaming\\python\\python39\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "jTuBznCkRPLP",
        "outputId": "b90a744d-376d-4090-8419-a8916a3047d2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\shafi\\anaconda3\\envs\\NN_SP\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">69,632</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m69,632\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,153</span> (473.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m121,153\u001b[0m (473.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">121,153</span> (473.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m121,153\u001b[0m (473.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Number of features (columns) in our input\n",
        "n_features = X_train.shape[2]\n",
        "\n",
        "model = Sequential([\n",
        "    LSTM(128, return_sequences=True, input_shape=(seq_length, n_features)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    LSTM(64),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "# Define callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
        "reduce_lr     = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5)\n",
        "model_checkpoint = ModelCheckpoint('lstm_best.keras', monitor='val_loss', save_best_only=True) # Changed to .keras\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J87wIWjaRgDf",
        "outputId": "491ced49-987f-4cb5-b607-72dc3fee20a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m 3432/22699\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:17\u001b[0m 7ms/step - loss: 0.0014 - mae: 0.0197"
          ]
        }
      ],
      "source": [
        "# 1. (Re)Train the model and save the best weights\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# 2. Check that the checkpoint file exists\n",
        "import os\n",
        "print(\"Files in working dir:\", os.listdir('.'))\n",
        "assert 'lstm_best.keras' in os.listdir('.'), \"Checkpoint file not found—did training complete?\"\n",
        "\n",
        "# 3. Load the best model (now that we know it’s there)\n",
        "from tensorflow.keras.models import load_model\n",
        "best_model = load_model('lstm_best.keras')\n",
        "\n",
        "# 4. Predict & compute metrics\n",
        "y_pred = best_model.predict(X_test)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae  = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Test RMSE (scaled): {rmse:.4f}\")\n",
        "print(f\"Test MAE  (scaled): {mae:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_mmeS9dRgsP"
      },
      "source": [
        "#### Step 4: Evaluate the Model\n",
        "\n",
        "Now that we’ve trained our model and saved the best weights (`lstm_best.h5`), let’s:\n",
        "\n",
        "1. **Load** the best model  \n",
        "2. **Predict** on the test set  \n",
        "3. **Compute** RMSE and MAE  \n",
        "4. (Optional) **Invert** the scaling on the target to get metrics in original units  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "_AEbM3UnDLyP",
        "outputId": "e3a2b8b1-9f81-4048-9221-c1f7a2895d4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy (filtered): 27.22%\n",
            " Test Accuracy (filtered):   76.54%\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "\n",
        "# 1. Filter out zero‐true samples\n",
        "mask = y_train != 0\n",
        "mape_train = mean_absolute_percentage_error(y_train[mask], y_train_pred[mask])\n",
        "acc_train  = 100 * (1 - mape_train)\n",
        "\n",
        "mask = y_test != 0\n",
        "mape_test = mean_absolute_percentage_error(y_test[mask], y_test_pred[mask])\n",
        "acc_test  = 100 * (1 - mape_test)\n",
        "\n",
        "print(f\"Training Accuracy (filtered): {acc_train:.2f}%\")\n",
        "print(f\" Test Accuracy (filtered):   {acc_test:.2f}%\")\n",
        "\n",
        "\n",
        "# 5. Bar‐chart visualization\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(['Train','Test'], [acc_train, acc_test], alpha=0.8)\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Training vs Test Accuracy')\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcRgbeZWRiYY",
        "outputId": "062b3218-40ae-4841-bed8-75cc27dacad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "Test RMSE (scaled): 0.0304\n",
            "Test MAE  (scaled): 0.0133\n",
            "Test RMSE (original): 0.2717 kW\n",
            "Test MAE  (original): 0.1190 kW\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "# 1. Load the best model\n",
        "best_model = load_model('lstm_best.keras')\n",
        "\n",
        "# 2. Predict on the test set\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# 3. Compute metrics on the scaled data\n",
        "rmse_scaled = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae_scaled  = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"Test RMSE (scaled): {rmse_scaled:.4f}\")\n",
        "print(f\"Test MAE  (scaled): {mae_scaled:.4f}\")\n",
        "\n",
        "# 4. (Optional) If you kept a separate scaler for Global_active_power:\n",
        "gap_scaler = MinMaxScaler(feature_range=(0,1)).fit(data[['Global_active_power']])\n",
        "y_test_inv = gap_scaler.inverse_transform(y_test.reshape(-1,1)).ravel()\n",
        "y_pred_inv = gap_scaler.inverse_transform(y_pred).ravel()\n",
        "rmse_orig = np.sqrt(mean_squared_error(y_test_inv, y_pred_inv))\n",
        "mae_orig  = mean_absolute_error(y_test_inv, y_pred_inv)\n",
        "print(f\"Test RMSE (original): {rmse_orig:.4f} kW\")\n",
        "print(f\"Test MAE  (original): {mae_orig:.4f} kW\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV3SY1ZoRoVv"
      },
      "source": [
        "#### Step 5: Hyperparameter Tuning with Keras Tuner\n",
        "\n",
        "We’ll use **Keras Tuner** to search over:\n",
        "- LSTM units in each layer  \n",
        "- Dropout rates  \n",
        "- Dense bottleneck size  \n",
        "- Learning rate  \n",
        "\n",
        "This automates finding better hyperparameters.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWYs1PF8vQw1",
        "outputId": "c3dc9c1f-7769-468b-b135-c9a69408d6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (14.0.0)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.9)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vK1UFmOyRpcA",
        "outputId": "00809335-cbd2-4d40-85d1-6f2e7353be9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 04m 32s]\n",
            "val_loss: 0.000858408777276054\n",
            "\n",
            "Best val_loss So Far: 0.0004279583226889372\n",
            "Total elapsed time: 01h 12m 09s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 22 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step\n",
            "Tuned Model Test RMSE (scaled): 0.0294\n",
            "Tuned Model Test MAE  (scaled): 0.0114\n"
          ]
        }
      ],
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    # LSTM layer 1\n",
        "    model.add(LSTM(\n",
        "        units=hp.Choice('units1', [32, 64, 128]),\n",
        "        return_sequences=True,\n",
        "        input_shape=(seq_length, n_features)\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout1', 0.1, 0.5, step=0.1)))\n",
        "    # LSTM layer 2\n",
        "    model.add(LSTM(\n",
        "        units=hp.Choice('units2', [32, 64, 128])\n",
        "    ))\n",
        "    model.add(Dropout(hp.Float('dropout2', 0.1, 0.5, step=0.1)))\n",
        "    # Dense bottleneck\n",
        "    model.add(Dense(hp.Int('dense_units', 16, 64, step=16), activation='relu'))\n",
        "    # Output\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=Adam(\n",
        "            learning_rate=hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
        "        ),\n",
        "        loss='mse',\n",
        "        metrics=['mae']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=2,\n",
        "    directory='lstm_tuning',\n",
        "    project_name='electricity_forecast'\n",
        ")\n",
        "\n",
        "# Search\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# Retrieve the best model\n",
        "best_hp_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the tuned model on test set\n",
        "y_pred_tuned = best_hp_model.predict(X_test)\n",
        "rmse_tuned = np.sqrt(mean_squared_error(y_test, y_pred_tuned))\n",
        "mae_tuned  = mean_absolute_error(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Tuned Model Test RMSE (scaled): {rmse_tuned:.4f}\")\n",
        "print(f\"Tuned Model Test MAE  (scaled): {mae_tuned:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePJI15mYRr9n"
      },
      "source": [
        "**Next Steps:**  \n",
        "- Compare `rmse_scaled` vs. `rmse_tuned` to confirm improvement.  \n",
        "- If needed, extend the search space (e.g., different sequence lengths, batch sizes).  \n",
        "- Consider BayesianOptimization tuner for more efficient hyperparameter search.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "NN_SP",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
